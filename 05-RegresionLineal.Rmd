---
title: "05-RegresionLineal"
author: "Jota"
date: "2024-11-01"
output: html_document
---




class: middle
background-image: url("images/5.png")
background-size: cover



.pull-left-narrow[



]

.pull-right-wide[

# Análitica Predictiva
----

]


---

# Análisis de regresión lineal

<br>

El objetivo del análisis de regresión es el de construir una función que aproxime de la mejor manera el comportamiento de una variable aletoaria $(Y)$ a través del conocimiento previo del valor de una variable explicativa $(X)$, mediante una expresión lineal como la siguiente:

<br>

.font180[$$Y = \beta_0 + \beta_1X$$]

<br>

> - Y: es llamada la variable de respuesta o dependiente
> - X: es llamada la variable predictora o independiente
> - $\beta_0$: es el intercepto de la linea con el eje $Y$
> - $\beta_1$: es la pendiente de la linea de regresión



---

class: center

## Este modelo supone una **asociación lineal** entre las variables de estudio, por tanto antes de empezar, esta relación debe ser valorada


.pull-left[

```{r, warning=FALSE, echo=FALSE, message=FALSE, fig.height=5}


retail_data <- mtcars %>%
  rename(
    sales_performance = mpg,
    product_category = cyl,
    product_size = disp,
    product_popularity = hp,
    profit_margin = drat,
    inventory_cost = wt,
    delivery_speed = qsec,
    product_lifespan = vs,
    sales_channel = am,
    supplier_diversity = gear,
    discount_frequency = carb
  )

# Verificar los nombres actualizados
#colnames(retail_data)

# Seleccionar solo las variables cuantitativas
retail_data_quant <- select(retail_data, sales_performance, product_size, 
                            product_popularity, profit_margin, 
                            inventory_cost, delivery_speed, 
                            supplier_diversity, discount_frequency)

# Graficar relación entre inventory_cost y sales_performance
plot(retail_data_quant$product_size, retail_data_quant$sales_performance, 
     main = "Relación entre Tamaño de producto y No. Ventas promedio",
     xlab = "Tamaño de producto cm3", ylab = "No. Ventas promedio")

# Calcular la correlación entre inventory_cost y sales_performance
#cor(retail_data_quant$product_size, retail_data_quant$sales_performance)



# cor(iris$Petal.Length,iris$Petal.Width)


```


.center[Correlación entre `Tamaño del producto` y `No. Ventas promedio` es -0.84. 

]


]



.pull-right[

```{r, warning=FALSE, echo=FALSE, message=FALSE, fig.height=6.5}

library(ggcorrplot)

cor_matrix <- cor(retail_data_quant)
ggcorrplot(cor_matrix, lab = TRUE, type = "lower", title = "Matriz de Correlación")


```



]


---

# Análisis de regresión lineal

<br>

El análisis de regresión se relaciona en gran medida con la estimación o predicción de la .orange[**media (de la población) o valor promedio de la variable dependiente,**] con base en los valores conocidos o fijos de las variables explicativas.

<br>

> Las observaciones de la variable $Y$ (dependiente) se asumen aleatorias de una distribución con media $E(Y|X=x)$. 

> Las desviaciones de las observaciones $y_i$ de la $E(Y|X=x)$ se tienen en cuenta adicionando un error aleatorio $u_i$ al siguiente modelo:

.font180[$$y_i = \beta_0 + \beta_1 x_i + u_i$$]


---

# Ejemplo

Estos datos se refieren a una tienda de retail que atiende a una población total de 60 clientes, organizados en función de su ingreso semanal $(X)$ y su consumo semanal en la tienda $(Y)$, en dólares. Los 60 clientes se dividen en 10 grupos de ingresos (de 80 dólares a 260), y para cada grupo de ingresos, se muestra cuánto consume semanalmente cada cliente en promedio. Por consiguiente, hay 10 niveles de $X$ y los correspondientes valores $Y$ para cada nivel de ingreso; así, se representan 10 subpoblaciones de consumo $Y$ en función del ingreso $X$.


.center[

<img src="images/ejm1.jpg" width="70%"/>

]


---

# Ejemplo

> En total hay 10 valores medios para las 10 subpoblaciones de Y. A estos valores medios se les llama valores esperados condicionales: $E(Y|X)$.

<br>

.pull-left[

Es importante distinguir entre los valores esperados condicionales y el valor esperado incondicional: $E(Y)$.


$$E(Y|X) \neq E(Y)$$



Si sumamos los consumos semanales de los 60 clientes que forman la población y dividimos este número entre 60, obtendremos la cantidad de 121.20 dólares (7272/60), que es el .orange[**valor de la media incondicional**], o esperada, del consumo semanal, $E(Y)$.

]

.pull-right[

.center[

<img src="https://media.giphy.com/media/hv53DaYcXWe3nRbR1A/giphy.gif" width="70%"/>

]

]


---

<br><br>

<img src="images/ejm2.jpg" width="90%"/>

### Esta figura muestra que para cada X (es decir, el nivel de ingresos) existe una población de valores Y (consumo semanal) que se distribuyen alrededor de la media (condicional) de dichos valores Y.



---


name: MCO
class: center, middle

# `r icon("database")`
# Mínimos cuadrados ordinarios
----


---



# MCO


.font140[En el análisis de regresión lineal el objetivo es utilizar los datos para trazar una línea que represente mejor la relación entre dos variables.]

.pull-left[

.center[

### Ya que se puede trazar más de una recta que razonablemente se ajuste a la distribución de los datos, es preferible utilizar el método de los **mínimos cuadrados** que resulta en una sola y mejor línea de regresión *.orange[(Recta del mejor ajuste)]*.
]
]

.pull-right[
<br>
.center[
<img src="https://media.giphy.com/media/W0R3W6eC7lkuOZYCYU/giphy.gif" width="70%"/>
]
]

> **Mínimos Cuadrados Ordinarios (MCO):** El objetivo de este procedimiento es estimar los parámetros tal que la suma de cuadrados (SC) de las diferencias entre las observaciones (valores reales) y la línea recta estimada sea mínima (Min SCError).



---

# MCO

Si lo que interesa es minimizar la suma de cuadrados del error...


.center[
### ¿Qué es el error?
]

--

.font1800[$$\hat{e}_i = y_i - \hat{y}_i$$]

### Entonces, interesa...


.pull-left[
.center[
<img src="images/Imagen7.jpg" width="90%"/>
]
]

.pull-right[

<br>
$$SCE = \sum_{i=1}^n (y_i - \hat{y}_i)^2$$
]

---

# MCO

### Minimizar SCE:

$$SCE = \sum_{i=1}^n (y_i - \hat{y}_i)^2 = \sum_{i=1}^n (y_i - (\hat{\beta_0} + \hat{\beta_1}x_i))^2$$


$$Min SCE =  \frac{\partial SCE}{\partial \hat{\beta_j}}$$

--

.font140[.orange[A partir de las ecuaciones normales se llega a:]]

.pull-left[

$$\hat{\beta_0} = \bar{y} - \hat{\beta_1}\bar{x}$$

]


.pull-right[


$$\begin{align}
\hat{\beta_1} & = & \frac{\sum_{i=1}^n x_i y_i - n \bar{x}\bar{y}}{\sum_{i=1}^n x_i^2 - n\bar{x}^2}   \nonumber \\
 & = & r \left( \frac{S_y}{S_x}\right)  \nonumber \\
 & = & \frac{cov(x,y)}{V(x)}
\end{align}$$


]




---


#MCO 

.font150[Una vez que se han determinado las estimaciones por MCO del intercepto y de la pendiente, se obtiene la línea de regresión de MCO.]

<br>

$$E(Y/X) = \hat{\beta_0} + \hat{\beta_1}{X}$$

$$\hat{Y} = \hat{\beta_0} + \hat{\beta_1}{X}$$

<br>
<br>

> - **El intercepto,** $\hat{\beta_0}$ es el valor predicho de Y cuando $X = 0$, aunque en algunos casos no tiene sentido hacer $X = 0$.

> - **La pendiente,** $\hat{\beta_1}$ es de primordial interés, pues indica la cantidad en la que cambia $\hat{Y}$ cuando X se incrementa en una unidad.



---



# Ejemplo en clase: .orange[Estimar]

.pull-left[

----

```{c1, warning=FALSE, message=FALSE, eval=FALSE, echo=TRUE}

modelo1 <- lm(sales_performance ~ product_size ,retail_data )
summary(modelo1)

```


----

.center[
.font110[**¿Cómo se interpreta esta ecuación?**
]]

.orange[$$\hat{Ventas} = 29.59 + -0.04 Tamaño$$]


- En este caso, el intercepto representa un .orange[**valor de ajuste**] que simplemente ayuda a formar la ecuación de la recta de regresión, pero no necesariamente tiene una interpretación.


- Luego, el cambio que se predice para las ventas en función del cambio en el tamaño se expresa como: 

$$\vartriangle \hat{Ventas} = 0.04 (\vartriangle Tamaño)$$


]


.pull-right[

.font40[
```{c1, warning=FALSE, message=FALSE, eval=FALSE, echo=TRUE}
## Call:
## lm(formula = sales_performance ~ product_size, data = retail_data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.8922 -2.2022 -0.9631  1.6272  7.2305 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept)  29.599855   1.229720  24.070  < 2e-16 ***
## product_size -0.041215   0.004712  -8.747 9.38e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 3.251 on 30 degrees of freedom
## Multiple R-squared:  0.7183,    Adjusted R-squared:  0.709 
## F-statistic: 76.51 on 1 and 30 DF,  p-value: 9.38e-10
```
]



Indica que por cada unidad (cm3) adicional en el tamaño del producto, el número promedio de ventas se reduce en 0.041 unidades.

]


---


# Estimación por Intervalos


Si se cumplen los supuestos del modelo de regresión lineal, entonces la distribución del estimador de MCO es normal y se puede utilizar para construir intervalos de confianza y hacer pruebas de hipótesis.

<br>
<br>

----

.center[

### Intervalos de Confianza para los Coeficientes

Un intervalo de confianza para un coeficiente $\beta_j$ es un rango de valores dentro del cual se espera que esté el verdadero valor del coeficiente con una cierta probabilidad.

]


----

---


# Intervalos de confianza para los coeficientes de regresión $\beta_0$ y $\beta_1$


.pull-left[

Un intervalo de confianza del $(1-\alpha)100%$ para el coeficiente de regresión $\beta_1$ está dado por:

$$\hat{\beta}_1 \pm t_{\alpha/2, n-2} \frac{\hat{\sigma}}{\sqrt{\sum_{i=1}^{n}(x_{i1}-\bar{x}_1)^2}}$$

El intervalo de confianza para el coeficiente de regresión $\beta_0$ es:

$$\hat{\beta}_0\pm t_{\alpha/2,n-2}\hat{\sigma}\sqrt{\frac{1}{n}+\frac{\bar{x}^2}{\sum_{i=1}^{n}(x_i-\bar{x})^2}}$$

]

.pull-right[

En ambos casos, $t_{\alpha/2,n-2}$ es el valor crítico de la distribución $t$ de Student con $n-2$ grados de libertad y un nivel de significancia $\alpha$.

La estimación del error estándar $\hat{\sigma}$ se calcula como:

$$\hat{\sigma}=\sqrt{CME}=\sqrt{\frac{\sum_{i=1}^{n}(y_i-\hat{y}_i)^2}{n-2}}$$

El intervalo de confianza nos indica que con un nivel de confianza de $1-\alpha$, el verdadero valor del coeficiente de regresión está contenido en el intervalo de confianza calculado.

]

.orange[**Nota:** Recuerda que] $t_{\alpha/2, n-2}$ .orange[es el valor crítico de la distribución] $t$ .orange[de Student con] $n-2$ .orange[grados de libertad, que deja una probabilidad de] $\alpha/2$ .orange[en la cola superior y] $\alpha/2$ .orange[en la cola inferior.]



---

# En R...

.pull-left[

En particular, para nuestro ejemplo:

```{c1, warning=FALSE, message=FALSE, eval=FALSE, echo=TRUE}

modelo1 <- lm(sales_performance ~ product_size ,retail_data )

summary(modelo1)
  
confint(modelo1)

  
# Esta es la salida

                   2.5 %      97.5 %
(Intercept)  27.08843246 32.11127705
product_size -0.05083797 -0.03159227
```


]

.pull-right[

> Estamos 95% seguros de que el valor promedio de ventas para productos de tamaño muy pequeño está entre 27.09 y 32.11 unidades. .orange[*Aunque un tamaño de producto igual a cero no tiene sentido práctico, este intervalo nos da una estimación del volumen de ventas para productos de menor tamaño.*]


----

- El intervalo de confianza del 95% para el coeficiente de product_size va de -0.0508 a -0.0316.

> Estamos 95% seguros de que el efecto del tamaño del producto en el número de ventas promedio se encuentra en este rango.


]





---



# Pruebas de hipótesis


* Hasta ahora, hemos estimado los coeficientes del modelo y hemos construido intervalos de confianza para ellos.

* Pero a veces, queremos hacer una afirmación más específica sobre el valor de un coeficiente en particular.

* Es aquí donde entran las pruebas de hipótesis.

## Hipótesis nula y alternativa

Las pruebas de hipótesis implican dos hipótesis:

> * Hipótesis nula. $H_0$: afirmación sobre el valor de un parámetro poblacional
> * Hipótesis alternativa. $H_1$: afirmación que contradice $H_0$

.orange[**Ejemplo:**]

$H_0$: $\beta_1 = 0$ (no hay relación entre X e Y) 

$H_1$: $\beta_1 \neq 0$ (hay una relación entre X e Y)

---

## Estadístico de prueba

Un estadístico de prueba es una función de los datos de la muestra que se utiliza para probar la hipótesis nula.

En el modelo lineal simple, el estadístico de prueba para probar la hipótesis nula:


$H_0: \beta_1 = \beta_{HipNula}$ es: 


$$t = \frac{\hat{\beta}_1 - \beta_{HipNula}}{ee(\hat{\beta}_1)}$$

donde,

* $\hat{\beta}_1$ es el estimador de máxima verosimilitud de $\beta_1$

* $ee(\hat{\beta}_1)$ es el error estándar de $\hat{\beta}1$

* $\beta_{HipNula}$ es el valor especificado en la hipótesis nula

---


.pull-left[

## Valor p

En lugar de establecer una región crítica, podemos utilizar el valor p para tomar una decisión.

El valor p es la probabilidad de obtener un valor del estadístico de prueba tan extremo o más extremo que el valor observado, asumiendo que la hipótesis nula es verdadera.

.orange[Si el valor p es menor que el nivel de significancia ] $\alpha$ .orange[rechazamos la hipótesis nula.]

## Regla $2t$

Si el número de grados de libertad es 20 o más, y si $\alpha$, el nivel de significancia, se fija en 0.05, se rechaza la hipótesis nula $\beta_1 = 0$ si el valor de $t = \hat{\beta_1}/ee(\hat{\beta_1})$ es superior a 2 en valor absoluto.

]

.pull-right[

## Prueba del intervalo de confianza


- Estimamos el intervalo de confianza al nivel de significancia $\alpha$ para $\beta_1$ usando la fórmula ya vista.

- .orange[Si el intervalo de confianza no contiene el valor 0, entonces rechazamos la hipótesis nula] y concluimos que hay evidencia estadística para afirmar que $\beta_1$ es diferente de cero al nivel de significancia $\alpha$. 

- En caso contrario, no podemos rechazar la hipótesis nula.

----



]

---

# En R...

Supongamos que tenemos un modelo de regresión lineal simple con una variable explicativa $x$ y una variable respuesta $y$. Queremos probar las siguientes hipótesis sobre los coeficientes de regresión:

<br>

> $H_0: \beta_1 = 0$ (la variable explicativa no tiene efecto sobre la variable respuesta)

> $H_1: \beta_1 \neq 0$ (la variable explicativa sí tiene efecto sobre la variable respuesta)

<br>

Podemos realizar la prueba de hipótesis utilizando la función `summary()` en R después de ajustar el modelo de regresión lineal simple. 

> La función `summary()` proporciona información sobre el modelo, incluyendo el valor del estadístico de prueba, el valor $p$ y el intervalo de confianza para los coeficientes de regresión.

---

# En R...


.pull-left[

`modelo1 <- lm(sales_performance ~ product_size ,retail_data )`

`summary(modelo1)`

* Dado que el valor $p$ (9.38e-10) es menor que cualquier nivel de significancia común, podemos rechazar la hipótesis nula y concluir que hay evidencia suficiente para afirmar que la variable Tamaño *(product_size)* tiene un efecto significativo en las Ventas *(sales_performance)*.

]

.pull-right[

.font70[
```{r, warning=FALSE, message=FALSE, eval=TRUE}
modelo1 <- lm(sales_performance ~ product_size ,retail_data )
summary(modelo1)
```
]

]



---




# Predicción

.pull-left[



* En muchas situaciones, nos interesa predecir el valor de una variable dependiente $Y$ para un conjunto de valores dados de las variables explicativas $X_1, X_2, ..., X_k$.

* Por ejemplo, podemos querer predecir la demanda de un producto en función de su precio y otros factores relacionados.

* El análisis de regresión nos permite modelar la relación entre las variables explicativas y la variable dependiente, y usar ese modelo para hacer predicciones.

]


.pull-right[


<img src="https://media.giphy.com/media/3otPot5ichOK0OWk3C/giphy.gif" width="90%">


]

---

# Predicción

Una vez que se han estimado los parámetros del modelo de regresión lineal simple, podemos usar el modelo para hacer predicciones.

----

La predicción puntual de $Y$ para un valor dado de $X$ es: 

$$\hat{Y} = \hat{\beta_0} + \hat{\beta_1} X$$

----


Donde $\hat{\beta_0}$ y $\hat{\beta_1}$ son las estimaciones de los parámetros $\beta_0$ y $\beta_1$ obtenidas a partir de los datos.

.orange[Es importante tener en cuenta que la predicción puntual solo es exacta si el modelo es válido y los errores son normales e independientes.]


---

# Predicción

## Intervalo de confianza para la predicción

Un intervalo de confianza para una nueva observación de $Y$ en el punto $X_0$ está dado por:

$$\hat{Y}_0 \pm t_{\alpha/2,n-2} \cdot \hat{\sigma} \sqrt{1 + \frac{1}{n} + \frac{(x_0-\bar{x})^2}{\sum_{i=1}^n (x_i - \bar{x})^2}}$$


Donde:

$\hat{Y}_0$ es la predicción puntual de $Y$ en $X_0$.

$t_{\alpha/2,n-2}$ es el valor crítico de $t$ con $(n-2)$ grados de libertad y un nivel de confianza $(1-\alpha)$.

$n$ es el tamaño de la muestra.

$\bar{X}$ es la media de las observaciones de $X$.

El intervalo de confianza nos indica el rango de valores en el que podemos esperar que caiga una nueva observación de $Y$ con una probabilidad $(1-\alpha)$.

---

# Predicción

## Intervalo de confianza para la predicción

Un intervalo de confianza para una nueva observación de $Y$ en el punto $X_0$ está dado por:

$$\hat{Y}_0 \pm t_{\alpha/2,n-2} \cdot \hat{\sigma} \sqrt{1 + \frac{1}{n} + \frac{(x_0-\bar{x})^2}{\sum_{i=1}^n (x_i - \bar{x})^2}}$$


.orange[**Intervalo de predicción:**] Se utiliza cuando la ecuación de regresión se emplea para predecir una Y individual para un valor de X dado.


.orange[**Ejemplo:**] Estimar el salario de un ejecutivo minorista en particular con
20 años de experiencia.


---

# Predicción

## Intervalo de confianza para la media

Un intervalo de confianza para la media de $Y$ está dado por:

$$\hat{Y}_0 \pm t_{\alpha/2,n-2} \cdot \hat{\sigma} \sqrt{\frac{1}{n} + \frac{(x_0-\bar{x})^2}{\sum_{i=1}^n (x_i - \bar{x})^2}}$$


.orange[**Intervalo de predicción media:**] Se utiliza cuando la ecuación de regresión se emplea para predecir el valor medio de Y para una X dada.


.orange[**Ejemplo:**] Se puede usar un intervalo de confianza para estimar el salario
medio de todos los ejecutivos en la industria minorista con base en sus años de experiencia.



---



# En R...


> .orange[**Para calcular el intervalo de confianza para la predicción,**] utilizamos la función `predict()` con el argumento `interval = "prediction"` y especificamos el nivel de confianza deseado con el argumento `level = 0.95`. Esto nos da tres columnas en la salida: la predicción puntual, el límite inferior del intervalo de confianza y el límite superior del intervalo de confianza.

----

> .orange[**Para calcular el intervalo de confianza para la predicción media,**] utilizamos la función `predict()` con el argumento `interval = "confidence"` y especificamos el nivel de confianza deseado con el argumento `level = 0.95`. Esto nos da tres columnas en la salida: la predicción puntual.




---


# En R...


.pull-left[

.scroll-box-20[

.font70[

```{r, eval=FALSE,echo=TRUE}

# Ajustar el modelo de regresión lineal simple
model <- lm(sales_performance ~ product_size, data = retail_data)

# Crear un conjunto de valores de product_size para la predicción
newdata <- data.frame(product_size = seq(from = min(retail_data$product_size), to = max(retail_data$product_size), length.out = 100))

# Calcular la predicción y el intervalo de confianza para la predicción
pred <- predict(model, newdata = newdata, interval = "prediction", level = 0.95)

# Calcular la predicción media y el intervalo de confianza para la predicción media
pred_mean <- predict(model, newdata = newdata, interval = "confidence", level = 0.95)

# Graficar los resultados
plot(retail_data$product_size, retail_data$sales_performance, pch = 16, xlab = "Tamaño", ylab = "Ventas")
lines(newdata$product_size, pred[, 1], lwd = 2, col = "blue")
lines(newdata$product_size, pred[, 2], lwd = 2, col = "red", lty = 2)
lines(newdata$product_size, pred[, 3], lwd = 2, col = "red", lty = 2)
lines(newdata$product_size, pred_mean[, 1], lwd = 2, col = "green")
lines(newdata$product_size, pred_mean[, 2], lwd = 2, col = "orange", lty = 2)
lines(newdata$product_size, pred_mean[, 3], lwd = 2, col = "orange", lty = 2)
legend("topright", legend = c("Predicción", "Intervalo de confianza para la predicción",
                              "Predicción media", "Intervalo de confianza para la predicción media"),
       lty = c(1, 2, 1, 2), col = c("blue", "red", "green", "orange"), bty = "n", cex = 0.8)

```

]
]
]


.pull-right[


```{r, echo=FALSE}

# Ajustar el modelo de regresión lineal simple
model <- lm(sales_performance ~ product_size, data = retail_data)

# Crear un conjunto de valores de product_size para la predicción
newdata <- data.frame(product_size = seq(from = min(retail_data$product_size), to = max(retail_data$product_size), length.out = 100))

# Calcular la predicción y el intervalo de confianza para la predicción
pred <- predict(model, newdata = newdata, interval = "prediction", level = 0.95)

# Calcular la predicción media y el intervalo de confianza para la predicción media
pred_mean <- predict(model, newdata = newdata, interval = "confidence", level = 0.95)

# Graficar los resultados
plot(retail_data$product_size, retail_data$sales_performance, pch = 16, xlab = "Tamaño", ylab = "Ventas")
lines(newdata$product_size, pred[, 1], lwd = 2, col = "blue")
lines(newdata$product_size, pred[, 2], lwd = 2, col = "red", lty = 2)
lines(newdata$product_size, pred[, 3], lwd = 2, col = "red", lty = 2)
lines(newdata$product_size, pred_mean[, 1], lwd = 2, col = "green")
lines(newdata$product_size, pred_mean[, 2], lwd = 2, col = "orange", lty = 2)
lines(newdata$product_size, pred_mean[, 3], lwd = 2, col = "orange", lty = 2)
legend("topright", legend = c("Predicción", "Intervalo de confianza para la predicción",
                              "Predicción media", "Intervalo de confianza para la predicción media"),
       lty = c(1, 2, 1, 2), col = c("blue", "red", "green", "orange"), bty = "n", cex = 0.8)

```

]

---




# Diagnóstico y evaluación del modelo

- La evaluación del modelo incluye la comprobación de las suposiciones de los residuos.

- Si los residuos no siguen una distribución normal o si hay patrones en los residuos, entonces es posible que el modelo no sea apropiado para realizar inferencias.

- También se pueden utilizar medidas como $R^2$ o el error cuadrático medio para evaluar la calidad del ajuste del modelo.

### En General,


- La forma matricial del modelo lineal múltiple es una herramienta poderosa para el análisis y la resolución de problemas de regresión.

- La interpretación de los coeficientes permite entender la relación entre las variables.

- La evaluación del modelo es esencial para verificar su validez y utilidad en la toma de decisiones.




---

# Validación de condiciones para la regresión múltiple lineal

> **Relación lineal entre los predictores numéricos y la variable respuesta:**


.pull-left[

Esta condición se puede validar bien mediante diagramas de dispersión entre la variable dependiente y cada uno de los predictores (como se ha hecho en el análisis preliminar).

]

.pull-right[

```{r, warning=FALSE, message=FALSE, eval=TRUE, echo=FALSE, fig.height=4}
plot(retail_data_quant$product_size, retail_data_quant$sales_performance, 
     main = "Relación entre Tamaño de producto y No. Ventas promedio",
     xlab = "Tamaño de producto", ylab = "Desempeño de Ventas")
```

]


---


<br>
<br>

> **Distribución normal de los residuos:**


Tanto el análisis gráfico como es test de hipótesis confirman la normalidad.

.pull-left[

```{r, warning=FALSE, message=FALSE, eval=TRUE, echo=TRUE, fig.height=4}

qqnorm(model$residuals)
qqline(model$residuals)


```

]


.pull-right[


> H0: Normalidad

> H1: No Normalidad


```{r, warning=FALSE, message=FALSE, eval=TRUE, echo=TRUE, fig.height=2}

shapiro.test(model$residuals)

```

]


---


<br>
<br>

> **Variabilidad constante de los residuos (homocedasticidad):**


.pull-left[

Al representar los residuos frente a los valores ajustados por el modelo, los primeros se tienen que distribuir de forma aleatoria en torno a cero, manteniendo aproximadamente la misma variabilidad a lo largo del eje X. 


Si se observa algún patrón específico, por ejemplo forma cónica o mayor dispersión en los extremos, significa que la variabilidad es dependiente del valor ajustado y por lo tanto no hay homocedasticidad.

<br>

> H0: Varianza Constante

> H1: Varianza No Constante


]


.pull-right[

```{r, warning=FALSE, message=FALSE, eval=FALSE, echo=TRUE, fig.height=2}

resi<-data.frame(model$fitted.values,model$residuals)

ggplot(data = resi, aes(model$fitted.values, model$residuals)) +
geom_point() +
geom_smooth(color = "firebrick", se = FALSE) +
geom_hline(yintercept = 0) +
theme_bw()


library(lmtest)
bptest(model)

```


]


---

> Variabilidad constante de los residuos (homocedasticidad):

No hay evidencias de falta de homocedasticidad, ante una significancia del 10%

```{r, warning=FALSE, message=FALSE, eval=TRUE, echo=FALSE, fig.height=2}

resi<-data.frame(model$fitted.values,model$residuals)

ggplot(data = resi, aes(model$fitted.values, model$residuals)) +
geom_point() +
geom_smooth(color = "firebrick", se = FALSE) +
geom_hline(yintercept = 0) +
theme_bw()

library(lmtest)
bptest(model)


```


---



# Regresión con variables categóricas

.pull-left[

```{r, warning=FALSE, message=FALSE, eval=TRUE, echo=FALSE, fig.height=2}

ggplot(retail_data, aes(x = product_size, y = sales_performance, color = as.factor(sales_channel))) +
  geom_point(size=4) +
  labs(x = "Tamaño del Producto", y = "Desempeño de Ventas", color = "Canal de Venta") +
  theme_minimal() +
  theme(legend.title = element_text(size = 12),   # Tamaño de fuente para el título de la leyenda
        legend.text = element_text(size = 10))   +  # Tamaño de fuente 
scale_color_manual(values = c("blue", "red"),  # Colores para cada categoría
                     labels = c("En Línea","Tienda Física")) 

```


- El modelo de regresión ajustado es:

$$
\text{Ventas} = \beta_0 + \beta_1 \cdot \text{Tamaño} + \beta_2 \cdot \text{Canal de Venta}
$$


----

- En este modelo, hemos incluido una **variable categórica**: `sales_channel`, que toma los valores **0** y **1**.
- Esta variable representa el **canal de venta**:
  - **0**: Tienda Física
  - **1**: En Línea


]



.pull-right[



**Coeficiente de `product_size`** $\beta_1$:
 - Mide el cambio promedio en las `Ventas` por cada unidad adicional en el tamaño del producto.
   
**Coeficiente de `sales_channel`** $\beta_2$:
 - Muestra la diferencia en las `Ventas` entre el canal de venta en línea (1) y el canal de tienda física (0).




]



---


# Regresión con variables categóricas

.pull-left[

```{r, warning=FALSE, message=FALSE, eval=TRUE, echo=FALSE, fig.height=2}

modelo2 <- lm(sales_performance ~ product_size +as.factor(sales_channel),
              retail_data )

summary(modelo2)

# Resultado:

## lm(formula = sales_performance ~ product_size + as.factor(sales_channel), 
##     data = retail_data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.6382 -2.4751 -0.5631  2.2333  6.8386 
## 
## Coefficients:
##                            Estimate Std. Error t value Pr(>|t|)    
## (Intercept)               27.848081   1.834071  15.184 2.45e-15 ***
## product_size              -0.036851   0.005782  -6.373 5.75e-07 ***
## as.factor(sales_channel)1  1.833458   1.436100   1.277    0.212    
## ---
## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
## 
## Residual standard error: 3.218 on 29 degrees of freedom
## Multiple R-squared:  0.7333,	Adjusted R-squared:  0.7149 
## F-statistic: 39.87 on 2 and 29 DF,  p-value: 4.749e-09  
  

```


]



.pull-right[

> **El coeficiente de 1.83** sugiere que el canal en línea tiende a tener un promedio de ventas 1.83 unidades mayor que el canal en tienda física.

----


> Sin embargo, **el valor de p = 0.212** indica que esta diferencia no es estadísticamente significativa al nivel de 0.05, por lo que no hay suficiente evidencia para afirmar que el canal de venta afecta el desempeño de ventas de forma significativa.


]



